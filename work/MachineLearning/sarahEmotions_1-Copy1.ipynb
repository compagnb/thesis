{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np #import numpy library\n",
    "import pandas as pd #import pandas library\n",
    "import matplotlib.pyplot as plt #import matplot library\n",
    "%matplotlib inline\n",
    "import nltk.classify.util\n",
    "from astropy.table import Table, Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4320, 23)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>heartrate</th>\n",
       "      <th>steps</th>\n",
       "      <th>calories</th>\n",
       "      <th>gsr</th>\n",
       "      <th>skintemp</th>\n",
       "      <th>airtemp</th>\n",
       "      <th>walk</th>\n",
       "      <th>run</th>\n",
       "      <th>bike</th>\n",
       "      <th>...</th>\n",
       "      <th>happy</th>\n",
       "      <th>happy score</th>\n",
       "      <th>calm</th>\n",
       "      <th>calm score</th>\n",
       "      <th>anxious</th>\n",
       "      <th>anxious score</th>\n",
       "      <th>sad</th>\n",
       "      <th>sad score</th>\n",
       "      <th>angry</th>\n",
       "      <th>angry score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4315</th>\n",
       "      <td>4/25/16 23:55</td>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>89.6</td>\n",
       "      <td>85.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4316</th>\n",
       "      <td>4/25/16 23:56</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>89.6</td>\n",
       "      <td>85.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4317</th>\n",
       "      <td>4/25/16 23:57</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>89.6</td>\n",
       "      <td>85.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4318</th>\n",
       "      <td>4/25/16 23:58</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>89.6</td>\n",
       "      <td>86.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4319</th>\n",
       "      <td>4/25/16 23:59</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>89.6</td>\n",
       "      <td>86.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          timestamp  heartrate  steps  calories       gsr  skintemp  airtemp  \\\n",
       "4315  4/25/16 23:55         71      0       1.1  0.000083      89.6     85.1   \n",
       "4316  4/25/16 23:56         70      0       1.0  0.000082      89.6     85.1   \n",
       "4317  4/25/16 23:57         69      0       1.0  0.000082      89.6     85.1   \n",
       "4318  4/25/16 23:58         68      0       1.1  0.000082      89.6     86.0   \n",
       "4319  4/25/16 23:59         69      0       1.0  0.000087      89.6     86.0   \n",
       "\n",
       "      walk  run  bike     ...       happy  happy score  calm  calm score  \\\n",
       "4315     1    0     0     ...           0            0     0           0   \n",
       "4316     1    0     0     ...           0            0     0           0   \n",
       "4317     1    0     0     ...           0            0     0           0   \n",
       "4318     0    0     0     ...           0            0     0           0   \n",
       "4319     0    0     0     ...           0            0     0           0   \n",
       "\n",
       "      anxious  anxious score  sad  sad score  angry  angry score  \n",
       "4315        0              0    0          0      0            0  \n",
       "4316        0              0    0          0      0            0  \n",
       "4317        0              0    0          0      0            0  \n",
       "4318        0              0    0          0      0            0  \n",
       "4319        0              0    0          0      0            0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load data\n",
    "saraTotal = pd.read_csv('sarahYee/sarahTotal.csv') #attach Amazon data to a var called data\n",
    "\n",
    "print(saraTotal.shape) #print data rows and columns\n",
    "# bioData.head(5) #limit data to 5 rows including a header row \n",
    "saraTotal.tail(5) #limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert summary NaNs into usable format\n",
    "saraTotal = saraTotal.fillna('0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#features extraction function -- thanks elena\n",
    "def bioFeaturesExtract(data):\n",
    "    '''Takes as an argument the original dataframe\n",
    "       Extracts number of unique users and products\n",
    "       as well as number of repeat users and product to user ratio\n",
    "       Returns Pandas dataframe with new features\n",
    "    '''\n",
    "\n",
    "    xHeart = data['heartrate'].astype(np.float64, copy=False)\n",
    "    xSteps = data['steps'].astype(np.float64, copy=False)\n",
    "    xCalories = data['calories'].astype(np.float64, copy=False)\n",
    "    xGsr = data['gsr'].astype(np.float64, copy=False)\n",
    "    xSkintemp = data['skintemp'].astype(np.float64, copy=False)\n",
    "    xAirtemp = data['airtemp'].astype(np.float64, copy=False)\n",
    "    \n",
    "    xTempDiff = xSkintemp - xAirtemp\n",
    "\n",
    "    names = np.array([ 'xHeart', 'xSteps', 'xCalories', 'xGsr', 'xSkintemp', 'xAirtemp', 'xTempDiff'])\n",
    "    result = np.array([ xHeart, xSteps, xCalories, xGsr, xSkintemp, xAirtemp, xTempDiff]).T\n",
    "    myFeatures = pd.DataFrame( result, columns = names )\n",
    "\n",
    "#     print(xGsr)\n",
    "\n",
    "    return myFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000059\n",
      "1       0.000059\n",
      "2       0.000062\n",
      "3       0.000059\n",
      "4       0.000061\n",
      "5       0.000060\n",
      "6       0.000061\n",
      "7       0.000061\n",
      "8       0.000060\n",
      "9       0.000057\n",
      "10      0.000060\n",
      "11      0.000060\n",
      "12      0.000061\n",
      "13      0.000059\n",
      "14      0.000063\n",
      "15      0.000058\n",
      "16      0.000058\n",
      "17      0.000058\n",
      "18      0.000057\n",
      "19      0.000058\n",
      "20      0.000058\n",
      "21      0.000057\n",
      "22      0.000059\n",
      "23      0.000060\n",
      "24      0.000068\n",
      "25      0.000059\n",
      "26      0.000057\n",
      "27      0.000058\n",
      "28      0.000057\n",
      "29      0.000057\n",
      "          ...   \n",
      "4290    0.000086\n",
      "4291    0.000088\n",
      "4292    0.000089\n",
      "4293    0.000089\n",
      "4294    0.000083\n",
      "4295    0.000084\n",
      "4296    0.000087\n",
      "4297    0.000085\n",
      "4298    0.000083\n",
      "4299    0.000090\n",
      "4300    0.000086\n",
      "4301    0.000093\n",
      "4302    0.000083\n",
      "4303    0.000079\n",
      "4304    0.000088\n",
      "4305    0.000084\n",
      "4306    0.000086\n",
      "4307    0.000086\n",
      "4308    0.000083\n",
      "4309    0.000083\n",
      "4310    0.000088\n",
      "4311    0.000084\n",
      "4312    0.000084\n",
      "4313    0.000083\n",
      "4314    0.000084\n",
      "4315    0.000083\n",
      "4316    0.000082\n",
      "4317    0.000082\n",
      "4318    0.000082\n",
      "4319    0.000087\n",
      "Name: gsr, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "biometric_analysis = bioFeaturesExtract(saraTotal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#features extraction function -- thanks elena\n",
    "def activityFeaturesExtract(data):\n",
    "    '''Takes as an argument the original dataframe\n",
    "       Extracts number of unique users and products\n",
    "       as well as number of repeat users and product to user ratio\n",
    "       Returns Pandas dataframe with new features\n",
    "    '''\n",
    "\n",
    "    xWalk = data['walk']\n",
    "    xRun = data['run']\n",
    "    xBike = data['bike']\n",
    "    xSleep = data['sleep']\n",
    "\n",
    "    names = np.array([ 'xWalk', 'xRun', 'xBike', 'xSleep'])\n",
    "    result = np.array([ xWalk, xRun, xBike, xSleep]).T\n",
    "    myFeatures = pd.DataFrame( result, columns = names )\n",
    "\n",
    "\n",
    "    return myFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "activity_analysis = activityFeaturesExtract(saraTotal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# xExcited = saraTotal.['excited '].values.reshape(saraTotal.shape[0], 1)\n",
    "xHappy = saraTotal.happy.values.reshape(saraTotal.shape[0], 1)\n",
    "xCalm = saraTotal.calm.values.reshape(saraTotal.shape[0], 1)\n",
    "xSad = saraTotal.sad.values.reshape(saraTotal.shape[0], 1)\n",
    "xAngry = saraTotal.angry.values.reshape(saraTotal.shape[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>heartrate</th>\n",
       "      <th>steps</th>\n",
       "      <th>calories</th>\n",
       "      <th>gsr</th>\n",
       "      <th>skintemp</th>\n",
       "      <th>airtemp</th>\n",
       "      <th>walk</th>\n",
       "      <th>run</th>\n",
       "      <th>bike</th>\n",
       "      <th>...</th>\n",
       "      <th>calm</th>\n",
       "      <th>calm score</th>\n",
       "      <th>anxious</th>\n",
       "      <th>anxious score</th>\n",
       "      <th>sad</th>\n",
       "      <th>sad score</th>\n",
       "      <th>angry</th>\n",
       "      <th>angry score</th>\n",
       "      <th>time</th>\n",
       "      <th>heart</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4/23/16 0:00</td>\n",
       "      <td>91</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>5.86e-05</td>\n",
       "      <td>92.3</td>\n",
       "      <td>89.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4/23/16 0:00</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4/23/16 0:01</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>5.86e-05</td>\n",
       "      <td>92.3</td>\n",
       "      <td>89.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4/23/16 0:01</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4/23/16 0:02</td>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>6.23e-05</td>\n",
       "      <td>92.3</td>\n",
       "      <td>89.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4/23/16 0:02</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4/23/16 0:03</td>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>5.86e-05</td>\n",
       "      <td>92.3</td>\n",
       "      <td>89.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4/23/16 0:03</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4/23/16 0:04</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>6.09e-05</td>\n",
       "      <td>92.3</td>\n",
       "      <td>89.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4/23/16 0:04</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      timestamp heartrate  steps  calories       gsr skintemp airtemp  walk  \\\n",
       "0  4/23/16 0:00        91      0       1.4  5.86e-05     92.3    89.6     0   \n",
       "1  4/23/16 0:01        92      0       1.5  5.86e-05     92.3    89.6     0   \n",
       "2  4/23/16 0:02        94      0       1.6  6.23e-05     92.3    89.6     0   \n",
       "3  4/23/16 0:03        95      0       1.7  5.86e-05     92.3    89.6     0   \n",
       "4  4/23/16 0:04        98      0       1.7  6.09e-05     92.3    89.6     0   \n",
       "\n",
       "   run  bike  ...    calm  calm score  anxious  anxious score  sad  sad score  \\\n",
       "0    0     0  ...       0           0        0              0    0          0   \n",
       "1    0     0  ...       0           0        0              0    0          0   \n",
       "2    0     0  ...       0           0        0              0    0          0   \n",
       "3    0     0  ...       0           0        0              0    0          0   \n",
       "4    0     0  ...       0           0        0              0    0          0   \n",
       "\n",
       "   angry  angry score          time  heart  \n",
       "0      0            0  4/23/16 0:00     91  \n",
       "1      0            0  4/23/16 0:01     92  \n",
       "2      0            0  4/23/16 0:02     94  \n",
       "3      0            0  4/23/16 0:03     95  \n",
       "4      0            0  4/23/16 0:04     98  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtoadd = np.concatenate((xHappy, xCalm, xAngry, xSad ), axis=1)\n",
    "\n",
    "saraTotal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#features extraction function -- thanks elena\n",
    "def emotionFeaturesExtract(data):\n",
    "    '''Takes as an argument the original dataframe\n",
    "       Extracts number of unique users and products\n",
    "       as well as number of repeat users and product to user ratio\n",
    "       Returns Pandas dataframe with new features\n",
    "    '''\n",
    "#     xExcited = data['excited '].reshape(-1, 1)\n",
    "#     xHappy = data['happy'].reshape(-1, 1)\n",
    "#     xCalm = data['calm'].reshape(-1, 1)\n",
    "# #     xAnxious = data['anxious']\n",
    "#     xSad = data['sad'].reshape(-1, 1)\n",
    "#     xAngry = data['angry'].reshape(-1, 1)\n",
    "\n",
    "#     names = np.array([ 'xExcited', 'xHappy', 'xCalm', 'xSad'])\n",
    "#     result = np.array([ xExcited, xHappy, xCalm, xSad]).T\n",
    "#     myFeatures = pd.DataFrame( result, columns = names )\n",
    "\n",
    "\n",
    "    return myFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Xtoadd = emotionFeaturesExtract(saraTotal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 91.    0.    1.4 ...,   0.    0.    0. ]\n",
      " [ 92.    0.    1.5 ...,   0.    0.    0. ]\n",
      " [ 94.    0.    1.6 ...,   0.    0.    0. ]\n",
      " ..., \n",
      " [ 69.    0.    1.  ...,   0.    0.    0. ]\n",
      " [ 68.    0.    1.1 ...,   0.    0.    0. ]\n",
      " [ 69.    0.    1.  ...,   0.    0.    0. ]]\n"
     ]
    }
   ],
   "source": [
    "X_counts = np.concatenate((biometric_analysis, activity_analysis), axis = 1)\n",
    "\n",
    "print(X_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# performance measures\n",
    "# report on training and test sets\n",
    "global SVMerror, SVMacc, SVMtp, SVMtn, LRerror, LRacc, LRtp, LRtn, NBerror, NBacc, NBtp, NBtn, Perror, Pacc, Ptp, Ptn\n",
    "\n",
    "\n",
    "\n",
    "def print_results(model):\n",
    "    #print('Error rate on training set: ')\n",
    "    erTRAIN = ((y_train != y_pred).sum() / X_train.shape[0])\n",
    "    #print('Accuracy rate on training set: ')\n",
    "    AccTRAIN = (1 - (y_train != y_pred).sum() / X_train.shape[0])\n",
    "    #print('True positive rate on training tet:')\n",
    "    TruPosTRAIN = ((y_train==True) & (y_pred==True)).sum() / y_train.sum()\n",
    "    #TruNegTEST = (((y_train==False) & (y_pred_train==False)).sum() / (y_train.shape[0] - y_train.sum()))\n",
    "    #print('**************')\n",
    "    #('Error rate on test set: ')\n",
    "    erTEST = ((y_test != y_pred_test).sum() / X_test.shape[0])\n",
    "    #print('Accuracy rate on test set: ')\n",
    "    AccTEST = (1 - (y_test != y_pred_test).sum() / X_test.shape[0])\n",
    "    #print('True positive rate on test set')\n",
    "    TruPosTEST = (((y_test==True) & (y_pred_test==True)).sum() / y_test.sum())\n",
    "    #print('True negative rate on test set')\n",
    "    TruNegTEST = (((y_test==False) & (y_pred_test==False)).sum() / (y_test.shape[0] - y_test.sum()))\n",
    "    data_rows = [('Error Rate', erTRAIN, erTEST),\n",
    "                 ('Accuracy Rate', AccTRAIN, AccTEST),\n",
    "                 ('True Positives', TruPosTRAIN, TruPosTEST),\n",
    "                 ('True Negatives', '--', TruNegTEST)]\n",
    "    t = Table(rows=data_rows, names=(model, 'Training Set', 'Test Set'), meta={'name': model + ': Training and Test Set Results'})\n",
    "    print(t)\n",
    "    if model == 'SVM':\n",
    "        SVMerror = erTEST\n",
    "        SVMacc = AccTEST\n",
    "        SVMtp = TruPosTEST\n",
    "        SVMtn = TruNegTEST\n",
    "        return(SVMerror, SVMacc, SVMtp, SVMtn)\n",
    "    elif model == 'Logistic Regression':\n",
    "        LRerror = erTEST\n",
    "        LRacc = AccTEST\n",
    "        LRtp = TruPosTEST\n",
    "        LRtn = TruNegTEST\n",
    "        return(LRerror, LRacc, LRtp, LRtn)\n",
    "    elif model == 'Naive Bayes':\n",
    "        NBerror = erTEST\n",
    "        NBacc = AccTEST\n",
    "        NBtp = TruPosTEST\n",
    "        NBtn = TruNegTEST\n",
    "        return(NBerror, NBacc, NBtp, NBtn)\n",
    "    elif model == 'Perceptron':\n",
    "        Perror = erTEST\n",
    "        Pacc = AccTEST\n",
    "        Ptp = TruPosTEST\n",
    "        Ptn = TruNegTEST\n",
    "        return(Perror, Pacc, Ptp, Ptn)\n",
    "    print('done')\n",
    "      \n",
    "    #t.show_in_browser(jsviewer=True) \n",
    "    \n",
    "    \n",
    "def all_models_table():\n",
    "    all_rows = [('SVM', SVMerror, SVMacc, SVMtp, SVMtn),\n",
    "            ('Logistic Regression', LRerror, LRacc, LRtp, LRtn),\n",
    "            ('Naive Bayes', NBerror, NBacc, NBtp, NBtn),\n",
    "            ('Perceptron', Perror, Pacc, Ptp, Ptn)]\n",
    "    tt = Table(rows=all_rows, names=('', 'Error Rate', 'Accuracy', 'True +', 'True -'), meta={'3/15/2016'})\n",
    "    print(tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (4320,15) into shape (4320)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-441-586b7abafe91>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcsr_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhstack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mXtoaddSparse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsr_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtoadd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mXfinal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_counts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXtoadd\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsr_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXfinal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/scipy/sparse/construct.py\u001b[0m in \u001b[0;36mhstack\u001b[0;34m(blocks, format, dtype)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m     \"\"\"\n\u001b[0;32m--> 464\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mbmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/scipy/sparse/construct.py\u001b[0m in \u001b[0;36mbmat\u001b[0;34m(blocks, format, dtype)\u001b[0m\n\u001b[1;32m    542\u001b[0m     \"\"\"\n\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 544\u001b[0;31m     \u001b[0mblocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'object'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    545\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m     \"\"\"\n\u001b[0;32m--> 474\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (4320,15) into shape (4320)"
     ]
    }
   ],
   "source": [
    "# convert additional features to sparse matrix and concatenate onto the bag of words sparse matrix\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "XtoaddSparse = csr_matrix(Xtoadd)\n",
    "Xfinal = hstack([X_counts, Xtoadd])\n",
    "X = csr_matrix(Xfinal)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4320,)"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y = saraTotal.anxious.values\n",
    "y = saraTotal.angry.values\n",
    "y.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create training and test sets\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "         X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def _assert_all_finite(X):\n",
    "#     \"\"\"Like assert_all_finite, but only for ndarray.\"\"\"\n",
    "#     X = np.asanyarray(X)\n",
    "#     # First try an O(n) time, O(1) space solution for the common case that\n",
    "#     # everything is finite; fall back to O(n) space np.isfinite to prevent\n",
    "#     # false positives from overflow in sum method.\n",
    "#     if (X.dtype.char in np.typecodes['AllFloat'] and not np.isfinite(X.sum())\n",
    "#             and not np.isfinite(X).all()):\n",
    "#         raise ValueError(\"Input contains NaN, infinity\"\n",
    "#                          \" or a value too large for %r.\" % X.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ..., 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# X_train = _assert_all_finite(X_train)\n",
    "# X_test = _assert_all_finite(X_test)\n",
    "\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler(with_mean=False)\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/utils/validation.py:386: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and willraise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found arrays with inconsistent numbers of samples: [   1 3024]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-414-6fd73fb3bca7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlinear_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGDClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m# y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# y_pred_test = clf.predict(X_test_std)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, coef_init, intercept_init, sample_weight)\u001b[0m\n\u001b[1;32m    543\u001b[0m                          \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m                          \u001b[0mcoef_init\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoef_init\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintercept_init\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mintercept_init\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m                          sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, alpha, C, loss, learning_rate, coef_init, intercept_init, sample_weight)\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'csr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"C\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 520\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         raise ValueError(\"Found arrays with inconsistent numbers of samples: \"\n\u001b[0;32m--> 176\u001b[0;31m                          \"%s\" % str(uniques))\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found arrays with inconsistent numbers of samples: [   1 3024]"
     ]
    }
   ],
   "source": [
    "# MODEL: SVM, linear\n",
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier()\n",
    "clf.fit(X_train_std, y_train)\n",
    "# y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "# y_pred_test = clf.predict(X_test_std)\n",
    "# print_results('SVM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The number of class labels must be greater than one.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-412-3c9f3659d1a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mpenalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'l2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpower_t\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         verbose=0, warm_start=False)\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_std\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_std\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_std\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0my_pred_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_std\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, coef_init, intercept_init, sample_weight)\u001b[0m\n\u001b[1;32m    543\u001b[0m                          \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m                          \u001b[0mcoef_init\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoef_init\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintercept_init\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mintercept_init\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m                          sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, alpha, C, loss, learning_rate, coef_init, intercept_init, sample_weight)\u001b[0m\n\u001b[1;32m    413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         self._partial_fit(X, y, alpha, C, loss, learning_rate, self.n_iter,\n\u001b[0;32m--> 415\u001b[0;31m                           classes, sample_weight, coef_init, intercept_init)\n\u001b[0m\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py\u001b[0m in \u001b[0;36m_partial_fit\u001b[0;34m(self, X, y, alpha, C, loss, learning_rate, n_iter, classes, sample_weight, coef_init, intercept_init)\u001b[0m\n\u001b[1;32m    377\u001b[0m                              sample_weight=sample_weight, n_iter=n_iter)\n\u001b[1;32m    378\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m             raise ValueError(\"The number of class labels must be \"\n\u001b[0m\u001b[1;32m    380\u001b[0m                              \"greater than one.\")\n\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The number of class labels must be greater than one."
     ]
    }
   ],
   "source": [
    "# MODEL: SVM, linear\n",
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier()\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results('SVM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X must be non-negative",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-386-996e532a4582>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnaive_bayes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMultinomialNB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultinomialNB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_std\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_std\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_std\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0my_pred_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_std\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    550\u001b[0m         self.feature_count_ = np.zeros((n_effective_classes, n_features),\n\u001b[1;32m    551\u001b[0m                                        dtype=np.float64)\n\u001b[0;32m--> 552\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_feature_log_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_class_log_prior\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_prior\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_prior\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36m_count\u001b[0;34m(self, X, Y)\u001b[0m\n\u001b[1;32m    653\u001b[0m         \u001b[0;34m\"\"\"Count and smooth feature occurrences.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Input X must be non-negative\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_count_\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_count_\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input X must be non-negative"
     ]
    }
   ],
   "source": [
    "# MODEL: Naive Bayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results('Naive Bayes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The number of class labels must be greater than one.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-387-ed7009f40e0b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlinear_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGDClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'perceptron'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_std\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_std\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_std\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0my_pred_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_std\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, coef_init, intercept_init, sample_weight)\u001b[0m\n\u001b[1;32m    543\u001b[0m                          \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m                          \u001b[0mcoef_init\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoef_init\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintercept_init\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mintercept_init\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m                          sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, alpha, C, loss, learning_rate, coef_init, intercept_init, sample_weight)\u001b[0m\n\u001b[1;32m    413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         self._partial_fit(X, y, alpha, C, loss, learning_rate, self.n_iter,\n\u001b[0;32m--> 415\u001b[0;31m                           classes, sample_weight, coef_init, intercept_init)\n\u001b[0m\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py\u001b[0m in \u001b[0;36m_partial_fit\u001b[0;34m(self, X, y, alpha, C, loss, learning_rate, n_iter, classes, sample_weight, coef_init, intercept_init)\u001b[0m\n\u001b[1;32m    377\u001b[0m                              sample_weight=sample_weight, n_iter=n_iter)\n\u001b[1;32m    378\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m             raise ValueError(\"The number of class labels must be \"\n\u001b[0m\u001b[1;32m    380\u001b[0m                              \"greater than one.\")\n\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The number of class labels must be greater than one."
     ]
    }
   ],
   "source": [
    "# Perceptron\n",
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier(loss='perceptron')\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results('Perceptron')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# features from Amazon.csv to add to feature set\n",
    "\n",
    "# Features pulled from review txt\n",
    "# data['reviewLen'] = data['Text'].str.len() #captures the amount of strings present in the review (i.e. review length)\n",
    "# data['hasEP'] = data['Text'].str.contains('!') #captures the presences of an exclaimation point\n",
    "saraTotal['time'] = saraTotal['timestamp']\n",
    "saraTotal['heart'] = saraTotal['heartrate']\n",
    "saraTotal['steps'] = saraTotal['steps']\n",
    "saraTotal['calories'] = saraTotal['calories']\n",
    "saraTotal['gsr'] = saraTotal['gsr']\n",
    "saraTotal['skintemp'] = saraTotal['skintemp']\n",
    "saraTotal['airtemp'] = saraTotal['airtemp']\n",
    "saraTotal['walk'] = saraTotal['walk']\n",
    "saraTotal['run'] = saraTotal['run']\n",
    "saraTotal['bike'] = saraTotal['bike']\n",
    "saraTotal['sleep'] = saraTotal['sleep']\n",
    "# saraTotal['tempDiff'] = saraTotal['skintemp'] - saraTotal['airtemp']\n",
    "\n",
    "# saraTotal['tempDiff'] = saraTotal['skintemp'] - saraTotal['airtemp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Taking values and making vectors\n",
    "# XScore = data.iloc[:, 7].values.reshape(data.shape[0], 1)\n",
    "# XreviewLen = data.iloc[:, 13].values.reshape(data.shape[0], 1)\n",
    "# XhasEP = data.iloc[:, 14].values.reshape(data.shape[0], 1)\n",
    "# XhasSemi = data.iloc[:, 15].values.reshape(data.shape[0], 1)\n",
    "\n",
    "# # tempDiff = saraTotal.iloc[:, 24].values.reshape(data.shape[0], 1)\n",
    "# time = saraTotal.iloc[:, 24].values.reshape(saraTotal.shape[0], 1)\n",
    "# heart = saraTotal.iloc[:, 25].values.reshape(saraTotal.shape[0], 1)\n",
    "# steps = saraTotal.iloc[:, 26].values.reshape(saraTotal.shape[0], 1)\n",
    "# calories = saraTotal.iloc[:, 27].values.reshape(saraTotal.shape[0], 1)\n",
    "# gsr = saraTotal.iloc[:, 28].values.reshape(saraTotal.shape[0], 1)\n",
    "# skintemp = saraTotal.iloc[:, 29].values.reshape(saraTotal.shape[0], 1)\n",
    "# airtemp = saraTotal.iloc[:, 30].values.reshape(saraTotal.shape[0], 1)\n",
    "# walk = saraTotal.iloc[:, 24].values.reshape(saraTotal.shape[0], 1)\n",
    "# run = saraTotal.iloc[:, 25].values.reshape(saraTotal.shape[0], 1)\n",
    "# bike = saraTotal.iloc[:, 26].values.reshape(saraTotal.shape[0], 1)\n",
    "# sleep = saraTotal.iloc[:, 27].values.reshape(saraTotal.shape[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input arrays must have same number of dimensions",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-425242e36e03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mXtoadd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcalories\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgsr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskintemp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mairtemp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwalk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbike\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msleep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msaraTotal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input arrays must have same number of dimensions"
     ]
    }
   ],
   "source": [
    "\n",
    "Xtoadd = np.concatenate((time, heart, steps, calories, gsr, skintemp, airtemp, walk, run, bike, sleep), axis=1)\n",
    "\n",
    "saraTotal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/ipykernel/__main__.py:2: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "y = saraTotal.iloc[:, 18].values\n",
    "y = np.where(y == 'true', -1, 1)\n",
    "\n",
    "# X = data.iloc[:, 35].values #punctuation count\n",
    "\n",
    "# plt.scatter(X[:50, 0], X[:50, 1],\n",
    "# ... color='red', marker='o', label='helpfulness')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# report on training and test sets\n",
    "global SVMerror, SVMacc, SVMtp, SVMtn, LRerror, LRacc, LRtp, LRtn, NBerror, NBacc, NBtp, NBtn, Perror, Pacc, Ptp, Ptn\n",
    "\n",
    "\n",
    "\n",
    "def print_results(model):\n",
    "    #print('Error rate on training set: ')\n",
    "    erTRAIN = ((y_train != y_pred).sum() / X_train.shape[0])\n",
    "    #print('Accuracy rate on training set: ')\n",
    "    AccTRAIN = (1 - (y_train != y_pred).sum() / X_train.shape[0])\n",
    "    #print('True positive rate on training tet:')\n",
    "    TruPosTRAIN = ((y_train==True) & (y_pred==True)).sum() / y_train.sum()\n",
    "    #TruNegTEST = (((y_train==False) & (y_pred_train==False)).sum() / (y_train.shape[0] - y_train.sum()))\n",
    "    #print('**************')\n",
    "    #('Error rate on test set: ')\n",
    "    erTEST = ((y_test != y_pred_test).sum() / X_test.shape[0])\n",
    "    #print('Accuracy rate on test set: ')\n",
    "    AccTEST = (1 - (y_test != y_pred_test).sum() / X_test.shape[0])\n",
    "    #print('True positive rate on test set')\n",
    "    TruPosTEST = (((y_test==True) & (y_pred_test==True)).sum() / y_test.sum())\n",
    "    #print('True negative rate on test set')\n",
    "    TruNegTEST = (((y_test==False) & (y_pred_test==False)).sum() / (y_test.shape[0] - y_test.sum()))\n",
    "    data_rows = [('Error Rate', erTRAIN, erTEST),\n",
    "                 ('Accuracy Rate', AccTRAIN, AccTEST),\n",
    "                 ('True Positives', TruPosTRAIN, TruPosTEST),\n",
    "                 ('True Negatives', '--', TruNegTEST)]\n",
    "    t = Table(rows=data_rows, names=(model, 'Training Set', 'Test Set'), meta={'name': model + ': Training and Test Set Results'})\n",
    "    print(t)\n",
    "    if model == 'SVM':\n",
    "        SVMerror = erTEST\n",
    "        SVMacc = AccTEST\n",
    "        SVMtp = TruPosTEST\n",
    "        SVMtn = TruNegTEST\n",
    "        return(SVMerror, SVMacc, SVMtp, SVMtn)\n",
    "    elif model == 'Logistic Regression':\n",
    "        LRerror = erTEST\n",
    "        LRacc = AccTEST\n",
    "        LRtp = TruPosTEST\n",
    "        LRtn = TruNegTEST\n",
    "        return(LRerror, LRacc, LRtp, LRtn)\n",
    "    elif model == 'Naive Bayes':\n",
    "        NBerror = erTEST\n",
    "        NBacc = AccTEST\n",
    "        NBtp = TruPosTEST\n",
    "        NBtn = TruNegTEST\n",
    "        return(NBerror, NBacc, NBtp, NBtn)\n",
    "    elif model == 'Perceptron':\n",
    "        Perror = erTEST\n",
    "        Pacc = AccTEST\n",
    "        Ptp = TruPosTEST\n",
    "        Ptn = TruNegTEST\n",
    "        return(Perror, Pacc, Ptp, Ptn)\n",
    "    print('done')\n",
    "      \n",
    "    #t.show_in_browser(jsviewer=True) \n",
    "    \n",
    "    \n",
    "def all_models_table():\n",
    "    all_rows = [('SVM', SVMerror, SVMacc, SVMtp, SVMtn),\n",
    "            ('Logistic Regression', LRerror, LRacc, LRtp, LRtn),\n",
    "            ('Naive Bayes', NBerror, NBacc, NBtp, NBtn),\n",
    "            ('Perceptron', Perror, Pacc, Ptp, Ptn)]\n",
    "    tt = Table(rows=all_rows, names=('', 'Error Rate', 'Accuracy', 'True +', 'True -'), meta={'3/15/2016'})\n",
    "    print(tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# vectorize Bag of Words from review text; as sparse matrix\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "hv = HashingVectorizer(n_features=2 ** 17, non_negative=True)\n",
    "X = hv.transform(data.Text)\n",
    "X.shape\n",
    "# (455000, 131072)\n",
    "\n",
    "# # vectorize Bag of Words from review text; as sparse matrix\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# tv = TfidfVectorizer(min_df=1, ngram_range=(2,17))\n",
    "# X = tv.fit_transform(data.Text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "no supported conversion for types: (dtype('O'),)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-9f29423803f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# convert additional features to sparse matrix and concatenate onto the bag of words sparse matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcsr_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhstack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mXtoaddSparse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsr_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtoadd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mXfinal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXtoaddSparse\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsr_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXfinal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/scipy/sparse/compressed.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, arg1, shape, dtype, copy)\u001b[0m\n\u001b[1;32m     67\u001b[0m                         self.format)\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcoo\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcoo_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_self\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoo_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;31m# Read matrix dimensions given, if any\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/scipy/sparse/compressed.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, arg1, shape, dtype, copy)\u001b[0m\n\u001b[1;32m     29\u001b[0m                 \u001b[0marg1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m                 \u001b[0marg1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_self\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36masformat\u001b[0;34m(self, format)\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'to'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;31m###################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/scipy/sparse/coo.py\u001b[0m in \u001b[0;36mtocsr\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    328\u001b[0m             \u001b[0mindptr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0midx_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnnz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0midx_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnnz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m             coo_tocsr(M, N, self.nnz,\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/scipy/sparse/sputils.py\u001b[0m in \u001b[0;36mupcast\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'no supported conversion for types: %r'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: no supported conversion for types: (dtype('O'),)"
     ]
    }
   ],
   "source": [
    "# convert additional features to sparse matrix and concatenate onto the bag of words sparse matrix\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "XtoaddSparse = csr_matrix(Xtoadd)\n",
    "Xfinal = hstack([X, XtoaddSparse])\n",
    "X = csr_matrix(Xfinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(455000,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define y\n",
    "y = data.iloc[:, 12].values\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create training and test sets\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "         X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler(with_mean=False)\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# decision tree classifier\n",
    "\n",
    "# from sklearn import tree\n",
    "# X = [[0, 0], [1, 1]]\n",
    "# Y = [0, 1]\n",
    "# clf = tree.DecisionTreeClassifier()\n",
    "# clf = clf.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     SVM          Training Set      Test Set   \n",
      "-------------- ----------------- --------------\n",
      "    Error Rate 0.000888540031397   0.1523003663\n",
      " Accuracy Rate    0.999111459969   0.8476996337\n",
      "True Positives    0.992853452729 0.444888577995\n",
      "True Negatives                -- 0.879566458223\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.15230036630036631,\n",
       " 0.84769963369963364,\n",
       " 0.44488857799540321,\n",
       " 0.87956645822298463)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODEL: SVM, linear\n",
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier()\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results('SVM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression    Training Set      Test Set   \n",
      "------------------- ----------------- --------------\n",
      "         Error Rate 0.000781789638932 0.144505494505\n",
      "      Accuracy Rate    0.999218210361 0.855494505495\n",
      "     True Positives    0.993714482521 0.433996202658\n",
      "     True Negatives                -- 0.888839698639\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.14450549450549449,\n",
       " 0.85549450549450556,\n",
       " 0.43399620265813932,\n",
       " 0.88883969863945045)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODEL: logistic regression\n",
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier(loss='log', n_iter=50, alpha=0.00001)\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results('Logistic Regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Naive Bayes     Training Set       Test Set   \n",
      "-------------- ---------------- ---------------\n",
      "    Error Rate 0.00194662480377 0.0805054945055\n",
      " Accuracy Rate   0.998053375196  0.919494505495\n",
      "True Positives   0.999354227656  0.328969721195\n",
      "True Negatives               --   0.96621156902\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.080505494505494504,\n",
       " 0.91949450549450551,\n",
       " 0.32896972119516338,\n",
       " 0.96621156901962957)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODEL: Naive Bayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results('Naive Bayes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Perceptron      Training Set      Test Set   \n",
      "-------------- ----------------- --------------\n",
      "    Error Rate 0.000813186813187 0.153282051282\n",
      " Accuracy Rate    0.999186813187 0.846717948718\n",
      "True Positives    0.993542276563 0.443089837114\n",
      "True Negatives                --  0.87864941143\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.15328205128205127,\n",
       " 0.8467179487179487,\n",
       " 0.44308983711402017,\n",
       " 0.87864941142988151)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perceptron\n",
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier(loss='perceptron')\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results('Perceptron')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
